{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 15:55:10.126859: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "%matplotlib inline\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from model_training import train_model, get_untrained_custom_model, plot_training_history\n",
    "from utils import save_model, load_data, test_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 15:55:11.746455: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2024-08-20 15:55:12.616337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-20 15:55:12.616382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3060 Laptop GPU computeCapability: 8.6\n",
      "coreClock: 1.425GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2024-08-20 15:55:12.616401: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-08-20 15:55:12.622176: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2024-08-20 15:55:12.622400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-08-20 15:55:12.623267: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2024-08-20 15:55:12.623612: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2024-08-20 15:55:12.624273: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2024-08-20 15:55:12.624913: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-08-20 15:55:12.625065: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-08-20 15:55:12.625181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-20 15:55:12.625213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-20 15:55:12.625227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "#making sure the gpu is available\n",
    "test_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 9940)\n"
     ]
    }
   ],
   "source": [
    "train_data_path = '../datasets/ready/train/'\n",
    "val_data_path = '../datasets/ready/val/'\n",
    "\n",
    "#loading the datasets\n",
    "x_train = load_data(train_data_path+\"x_train.csv\")\n",
    "y_train = load_data(train_data_path+\"y_train.csv\")\n",
    "x_val = load_data(val_data_path+\"/x_val.csv\")\n",
    "y_val = load_data(val_data_path+\"/y_val.csv\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../models/model.h5'\n",
    "# Setting up hyperparameters\n",
    "batch_size = 256\n",
    "epochs = 256\n",
    "\n",
    "optimizer='adam'\n",
    "loss='binary_crossentropy' \n",
    "metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 15:55:14.336082: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-20 15:55:14.337749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-20 15:55:14.337789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3060 Laptop GPU computeCapability: 8.6\n",
      "coreClock: 1.425GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2024-08-20 15:55:14.337821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-20 15:55:14.337841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-20 15:55:14.337853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2024-08-20 15:55:14.337901: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-08-20 15:55:16.132962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-08-20 15:55:16.133004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2024-08-20 15:55:16.133010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2024-08-20 15:55:16.133501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-20 15:55:16.133581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-20 15:55:16.133587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1501] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-08-20 15:55:16.133620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-20 15:55:16.133685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3436 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "# Getting the model\n",
    "model = get_untrained_custom_model(optimizer=optimizer, loss=loss, metrics=metrics, x_train=x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 15:55:16.414220: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2024-08-20 15:55:16.414657: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2495995000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 15:55:16.802829: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 149ms/step - loss: 0.7086 - accuracy: 0.5000 - val_loss: 0.7058 - val_accuracy: 0.6000\n",
      "Epoch 2/256\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7035 - accuracy: 0.7188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 15:55:18.007479: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-08-20 15:55:18.007736: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7033 - accuracy: 0.7171 - val_loss: 0.7035 - val_accuracy: 0.5867\n",
      "Epoch 3/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6987 - accuracy: 0.8086 - val_loss: 0.7015 - val_accuracy: 0.6000\n",
      "Epoch 4/256\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6941 - accuracy: 0.8743 - val_loss: 0.6995 - val_accuracy: 0.6400\n",
      "Epoch 5/256\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6893 - accuracy: 0.9000 - val_loss: 0.6976 - val_accuracy: 0.6667\n",
      "Epoch 6/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6850 - accuracy: 0.9086 - val_loss: 0.6959 - val_accuracy: 0.6933\n",
      "Epoch 7/256\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6815 - accuracy: 0.9314 - val_loss: 0.6945 - val_accuracy: 0.6933\n",
      "Epoch 8/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6759 - accuracy: 0.9486 - val_loss: 0.6934 - val_accuracy: 0.7067\n",
      "Epoch 9/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6723 - accuracy: 0.9571 - val_loss: 0.6925 - val_accuracy: 0.7200\n",
      "Epoch 10/256\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6663 - accuracy: 0.9600 - val_loss: 0.6917 - val_accuracy: 0.7200\n",
      "Epoch 11/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6632 - accuracy: 0.9629 - val_loss: 0.6911 - val_accuracy: 0.7200\n",
      "Epoch 12/256\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6577 - accuracy: 0.9771 - val_loss: 0.6905 - val_accuracy: 0.7200\n",
      "Epoch 13/256\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6528 - accuracy: 0.9743 - val_loss: 0.6899 - val_accuracy: 0.7333\n",
      "Epoch 14/256\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6523 - accuracy: 0.9829 - val_loss: 0.6895 - val_accuracy: 0.7467\n",
      "Epoch 15/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6470 - accuracy: 0.9829 - val_loss: 0.6892 - val_accuracy: 0.7467\n",
      "Epoch 16/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6436 - accuracy: 0.9800 - val_loss: 0.6891 - val_accuracy: 0.7600\n",
      "Epoch 17/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6412 - accuracy: 0.9657 - val_loss: 0.6889 - val_accuracy: 0.7600\n",
      "Epoch 18/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6357 - accuracy: 0.9857 - val_loss: 0.6888 - val_accuracy: 0.7600\n",
      "Epoch 19/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6309 - accuracy: 0.9914 - val_loss: 0.6886 - val_accuracy: 0.7600\n",
      "Epoch 20/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6246 - accuracy: 0.9829 - val_loss: 0.6883 - val_accuracy: 0.7600\n",
      "Epoch 21/256\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6248 - accuracy: 0.9857 - val_loss: 0.6882 - val_accuracy: 0.7733\n",
      "Epoch 22/256\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6225 - accuracy: 0.9829 - val_loss: 0.6880 - val_accuracy: 0.7600\n",
      "Epoch 23/256\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6196 - accuracy: 0.9943 - val_loss: 0.6879 - val_accuracy: 0.7867\n",
      "Epoch 24/256\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6126 - accuracy: 0.9886 - val_loss: 0.6878 - val_accuracy: 0.7867\n",
      "Epoch 25/256\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6119 - accuracy: 0.9914 - val_loss: 0.6879 - val_accuracy: 0.8000\n",
      "Epoch 26/256\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6073 - accuracy: 0.9857 - val_loss: 0.6879 - val_accuracy: 0.8000\n",
      "Epoch 27/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6059 - accuracy: 0.9886 - val_loss: 0.6880 - val_accuracy: 0.8000\n",
      "Epoch 28/256\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5994 - accuracy: 0.9886 - val_loss: 0.6880 - val_accuracy: 0.8000\n",
      "Epoch 29/256\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6003 - accuracy: 0.9914 - val_loss: 0.6879 - val_accuracy: 0.7867\n",
      "Epoch 30/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5931 - accuracy: 0.9943 - val_loss: 0.6878 - val_accuracy: 0.7867\n",
      "Epoch 31/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5940 - accuracy: 0.9857 - val_loss: 0.6879 - val_accuracy: 0.7867\n",
      "Epoch 32/256\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5866 - accuracy: 0.9914 - val_loss: 0.6880 - val_accuracy: 0.7867\n",
      "Epoch 33/256\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5855 - accuracy: 0.9771 - val_loss: 0.6881 - val_accuracy: 0.7867\n",
      "Epoch 34/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5888 - accuracy: 0.9829 - val_loss: 0.6881 - val_accuracy: 0.7867\n",
      "Epoch 35/256\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5814 - accuracy: 0.9943 - val_loss: 0.6883 - val_accuracy: 0.7733\n",
      "Epoch 36/256\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5818 - accuracy: 0.9943 - val_loss: 0.6884 - val_accuracy: 0.7733\n",
      "Epoch 37/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5779 - accuracy: 0.9857 - val_loss: 0.6885 - val_accuracy: 0.7733\n",
      "Epoch 38/256\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5720 - accuracy: 0.9914 - val_loss: 0.6887 - val_accuracy: 0.7733\n",
      "Epoch 39/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5699 - accuracy: 0.9829 - val_loss: 0.6887 - val_accuracy: 0.7733\n",
      "Epoch 40/256\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5730 - accuracy: 0.9943 - val_loss: 0.6887 - val_accuracy: 0.7733\n",
      "Epoch 41/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5620 - accuracy: 0.9943 - val_loss: 0.6886 - val_accuracy: 0.7733\n",
      "Epoch 42/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5650 - accuracy: 0.9914 - val_loss: 0.6886 - val_accuracy: 0.7733\n",
      "Epoch 43/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5645 - accuracy: 0.9829 - val_loss: 0.6888 - val_accuracy: 0.7733\n",
      "Epoch 44/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5574 - accuracy: 0.9829 - val_loss: 0.6891 - val_accuracy: 0.7733\n",
      "Epoch 45/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5601 - accuracy: 0.9857 - val_loss: 0.6893 - val_accuracy: 0.7733\n",
      "Epoch 46/256\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5552 - accuracy: 0.9886 - val_loss: 0.6895 - val_accuracy: 0.7867\n",
      "Epoch 47/256\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5565 - accuracy: 0.9943 - val_loss: 0.6898 - val_accuracy: 0.7733\n",
      "Epoch 48/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5429 - accuracy: 0.9943 - val_loss: 0.6900 - val_accuracy: 0.7867\n",
      "Epoch 49/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5534 - accuracy: 0.9857 - val_loss: 0.6902 - val_accuracy: 0.7867\n",
      "Epoch 50/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5425 - accuracy: 0.9857 - val_loss: 0.6903 - val_accuracy: 0.8000\n",
      "Epoch 51/256\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5387 - accuracy: 0.9943 - val_loss: 0.6904 - val_accuracy: 0.7867\n",
      "Epoch 52/256\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5476 - accuracy: 0.9914 - val_loss: 0.6904 - val_accuracy: 0.7867\n",
      "Epoch 53/256\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5349 - accuracy: 0.9914 - val_loss: 0.6907 - val_accuracy: 0.7867\n",
      "Epoch 54/256\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5323 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.8133\n",
      "Epoch 55/256\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5317 - accuracy: 0.9971 - val_loss: 0.6911 - val_accuracy: 0.8133\n",
      "Epoch 56/256\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5251 - accuracy: 0.9914 - val_loss: 0.6913 - val_accuracy: 0.8133\n",
      "Epoch 57/256\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5280 - accuracy: 0.9914 - val_loss: 0.6913 - val_accuracy: 0.8133\n",
      "Epoch 58/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5209 - accuracy: 0.9943 - val_loss: 0.6914 - val_accuracy: 0.8000\n",
      "Epoch 59/256\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5253 - accuracy: 0.9857 - val_loss: 0.6917 - val_accuracy: 0.8133\n",
      "Epoch 60/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5203 - accuracy: 0.9971 - val_loss: 0.6919 - val_accuracy: 0.8133\n",
      "Epoch 61/256\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5198 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8133\n",
      "Epoch 62/256\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5127 - accuracy: 0.9886 - val_loss: 0.6919 - val_accuracy: 0.8000\n",
      "Epoch 63/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5120 - accuracy: 0.9886 - val_loss: 0.6920 - val_accuracy: 0.8000\n",
      "Epoch 64/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5091 - accuracy: 0.9943 - val_loss: 0.6921 - val_accuracy: 0.8000\n",
      "Epoch 65/256\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5080 - accuracy: 0.9971 - val_loss: 0.6921 - val_accuracy: 0.8000\n",
      "Epoch 66/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5031 - accuracy: 0.9943 - val_loss: 0.6923 - val_accuracy: 0.8000\n",
      "Epoch 67/256\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5029 - accuracy: 0.9914 - val_loss: 0.6924 - val_accuracy: 0.8000\n",
      "Epoch 68/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5184 - accuracy: 0.9886 - val_loss: 0.6925 - val_accuracy: 0.8000\n",
      "Epoch 69/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5062 - accuracy: 0.9857 - val_loss: 0.6927 - val_accuracy: 0.7867\n",
      "Epoch 70/256\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5025 - accuracy: 0.9857 - val_loss: 0.6929 - val_accuracy: 0.7733\n",
      "Epoch 71/256\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4874 - accuracy: 0.9971 - val_loss: 0.6930 - val_accuracy: 0.7733\n",
      "Epoch 72/256\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4989 - accuracy: 0.9829 - val_loss: 0.6929 - val_accuracy: 0.7733\n",
      "Epoch 73/256\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4928 - accuracy: 0.9971 - val_loss: 0.6929 - val_accuracy: 0.7733\n",
      "Epoch 74/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4929 - accuracy: 0.9971 - val_loss: 0.6930 - val_accuracy: 0.7733\n",
      "Epoch 75/256\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4927 - accuracy: 0.9943 - val_loss: 0.6932 - val_accuracy: 0.7733\n",
      "Epoch 76/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4917 - accuracy: 0.9914 - val_loss: 0.6934 - val_accuracy: 0.7733\n",
      "Epoch 77/256\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4865 - accuracy: 0.9971 - val_loss: 0.6936 - val_accuracy: 0.7733\n",
      "Epoch 78/256\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4838 - accuracy: 0.9971 - val_loss: 0.6938 - val_accuracy: 0.7867\n",
      "Epoch 79/256\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4934 - accuracy: 0.9914 - val_loss: 0.6939 - val_accuracy: 0.7867\n",
      "Epoch 80/256\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4893 - accuracy: 0.9857 - val_loss: 0.6938 - val_accuracy: 0.7867\n",
      "Epoch 81/256\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4847 - accuracy: 0.9971 - val_loss: 0.6937 - val_accuracy: 0.7733\n",
      "Epoch 82/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4757 - accuracy: 0.9914 - val_loss: 0.6937 - val_accuracy: 0.7733\n",
      "Epoch 83/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4846 - accuracy: 0.9914 - val_loss: 0.6936 - val_accuracy: 0.7733\n",
      "Epoch 84/256\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4759 - accuracy: 0.9886 - val_loss: 0.6936 - val_accuracy: 0.7733\n",
      "Epoch 85/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4749 - accuracy: 0.9943 - val_loss: 0.6936 - val_accuracy: 0.7733\n",
      "Epoch 86/256\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4723 - accuracy: 0.9886 - val_loss: 0.6937 - val_accuracy: 0.7733\n",
      "Epoch 87/256\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4676 - accuracy: 0.9857 - val_loss: 0.6937 - val_accuracy: 0.7733\n",
      "Epoch 88/256\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4723 - accuracy: 0.9886 - val_loss: 0.6936 - val_accuracy: 0.7733\n",
      "Epoch 89/256\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4691 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.7733\n",
      "Epoch 90/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4581 - accuracy: 0.9914 - val_loss: 0.6938 - val_accuracy: 0.7867\n",
      "Epoch 91/256\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4719 - accuracy: 0.9943 - val_loss: 0.6938 - val_accuracy: 0.7867\n",
      "Epoch 92/256\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4678 - accuracy: 0.9914 - val_loss: 0.6938 - val_accuracy: 0.8000\n",
      "Epoch 93/256\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4595 - accuracy: 0.9914 - val_loss: 0.6937 - val_accuracy: 0.8000\n",
      "Epoch 94/256\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4630 - accuracy: 0.9886 - val_loss: 0.6936 - val_accuracy: 0.8000\n",
      "Epoch 95/256\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4579 - accuracy: 0.9829 - val_loss: 0.6934 - val_accuracy: 0.7733\n",
      "Epoch 96/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4657 - accuracy: 0.9914 - val_loss: 0.6934 - val_accuracy: 0.7867\n",
      "Epoch 97/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4539 - accuracy: 0.9971 - val_loss: 0.6935 - val_accuracy: 0.8000\n",
      "Epoch 98/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4509 - accuracy: 0.9886 - val_loss: 0.6935 - val_accuracy: 0.8000\n",
      "Epoch 99/256\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4549 - accuracy: 0.9971 - val_loss: 0.6934 - val_accuracy: 0.8000\n",
      "Epoch 100/256\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4517 - accuracy: 0.9943 - val_loss: 0.6932 - val_accuracy: 0.7867\n",
      "Epoch 101/256\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4704 - accuracy: 0.9886 - val_loss: 0.6930 - val_accuracy: 0.7867\n",
      "Epoch 102/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4445 - accuracy: 0.9943 - val_loss: 0.6929 - val_accuracy: 0.7867\n",
      "Epoch 103/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4486 - accuracy: 0.9886 - val_loss: 0.6926 - val_accuracy: 0.7733\n",
      "Epoch 104/256\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4482 - accuracy: 0.9943 - val_loss: 0.6926 - val_accuracy: 0.7733\n",
      "Epoch 105/256\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4403 - accuracy: 0.9943 - val_loss: 0.6926 - val_accuracy: 0.7733\n",
      "Epoch 106/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4425 - accuracy: 0.9971 - val_loss: 0.6926 - val_accuracy: 0.7600\n",
      "Epoch 107/256\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4370 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.7600\n",
      "Epoch 108/256\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4405 - accuracy: 0.9943 - val_loss: 0.6925 - val_accuracy: 0.7733\n",
      "Epoch 109/256\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4399 - accuracy: 0.9971 - val_loss: 0.6924 - val_accuracy: 0.7733\n",
      "Epoch 110/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4315 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.7733\n",
      "Epoch 111/256\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4431 - accuracy: 0.9914 - val_loss: 0.6921 - val_accuracy: 0.7733\n",
      "Epoch 112/256\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4395 - accuracy: 0.9971 - val_loss: 0.6919 - val_accuracy: 0.7733\n",
      "Epoch 113/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4358 - accuracy: 0.9914 - val_loss: 0.6917 - val_accuracy: 0.7733\n",
      "Epoch 114/256\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4291 - accuracy: 0.9971 - val_loss: 0.6917 - val_accuracy: 0.7733\n",
      "Epoch 115/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4344 - accuracy: 0.9857 - val_loss: 0.6916 - val_accuracy: 0.7733\n",
      "Epoch 116/256\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4296 - accuracy: 0.9971 - val_loss: 0.6915 - val_accuracy: 0.7733\n",
      "Epoch 117/256\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4273 - accuracy: 0.9886 - val_loss: 0.6915 - val_accuracy: 0.7867\n",
      "Epoch 118/256\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4275 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.7867\n",
      "Epoch 119/256\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4212 - accuracy: 0.9971 - val_loss: 0.6913 - val_accuracy: 0.7867\n",
      "Epoch 120/256\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4223 - accuracy: 0.9971 - val_loss: 0.6911 - val_accuracy: 0.7867\n",
      "Epoch 121/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4309 - accuracy: 0.9943 - val_loss: 0.6910 - val_accuracy: 0.7867\n",
      "Epoch 122/256\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4294 - accuracy: 0.9943 - val_loss: 0.6907 - val_accuracy: 0.7867\n",
      "Epoch 123/256\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4202 - accuracy: 0.9971 - val_loss: 0.6904 - val_accuracy: 0.7867\n",
      "Epoch 124/256\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4197 - accuracy: 0.9914 - val_loss: 0.6900 - val_accuracy: 0.7733\n",
      "Epoch 125/256\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4275 - accuracy: 0.9971 - val_loss: 0.6897 - val_accuracy: 0.7733\n",
      "Epoch 126/256\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4253 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.7733\n",
      "Epoch 127/256\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4172 - accuracy: 0.9971 - val_loss: 0.6893 - val_accuracy: 0.7733\n",
      "Epoch 128/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4165 - accuracy: 0.9971 - val_loss: 0.6891 - val_accuracy: 0.7733\n",
      "Epoch 129/256\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4255 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.7733\n",
      "Epoch 130/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4258 - accuracy: 0.9943 - val_loss: 0.6889 - val_accuracy: 0.7733\n",
      "Epoch 131/256\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4141 - accuracy: 0.9886 - val_loss: 0.6890 - val_accuracy: 0.7733\n",
      "Epoch 132/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4226 - accuracy: 0.9943 - val_loss: 0.6891 - val_accuracy: 0.7867\n",
      "Epoch 133/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4184 - accuracy: 0.9971 - val_loss: 0.6890 - val_accuracy: 0.7733\n",
      "Epoch 134/256\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4157 - accuracy: 0.9857 - val_loss: 0.6886 - val_accuracy: 0.7600\n",
      "Epoch 135/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4170 - accuracy: 0.9943 - val_loss: 0.6883 - val_accuracy: 0.7600\n",
      "Epoch 136/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4080 - accuracy: 0.9971 - val_loss: 0.6880 - val_accuracy: 0.7600\n",
      "Epoch 137/256\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4076 - accuracy: 0.9971 - val_loss: 0.6878 - val_accuracy: 0.7600\n",
      "Epoch 138/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4153 - accuracy: 0.9943 - val_loss: 0.6875 - val_accuracy: 0.7600\n",
      "Epoch 139/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4103 - accuracy: 0.9914 - val_loss: 0.6873 - val_accuracy: 0.7600\n",
      "Epoch 140/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4060 - accuracy: 0.9914 - val_loss: 0.6871 - val_accuracy: 0.7733\n",
      "Epoch 141/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3968 - accuracy: 0.9971 - val_loss: 0.6870 - val_accuracy: 0.7733\n",
      "Epoch 142/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4039 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.7867\n",
      "Epoch 143/256\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3958 - accuracy: 0.9943 - val_loss: 0.6871 - val_accuracy: 0.7867\n",
      "Epoch 144/256\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4020 - accuracy: 0.9971 - val_loss: 0.6871 - val_accuracy: 0.7867\n",
      "Epoch 145/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3930 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.7867\n",
      "Epoch 146/256\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3988 - accuracy: 0.9914 - val_loss: 0.6865 - val_accuracy: 0.7867\n",
      "Epoch 147/256\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4005 - accuracy: 0.9971 - val_loss: 0.6862 - val_accuracy: 0.7867\n",
      "Epoch 148/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4009 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.7733\n",
      "Epoch 149/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3973 - accuracy: 1.0000 - val_loss: 0.6854 - val_accuracy: 0.7733\n",
      "Epoch 150/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3968 - accuracy: 0.9914 - val_loss: 0.6852 - val_accuracy: 0.7733\n",
      "Epoch 151/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3975 - accuracy: 0.9943 - val_loss: 0.6851 - val_accuracy: 0.7867\n",
      "Epoch 152/256\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3978 - accuracy: 0.9971 - val_loss: 0.6850 - val_accuracy: 0.7867\n",
      "Epoch 153/256\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3979 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.7867\n",
      "Epoch 154/256\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3931 - accuracy: 0.9886 - val_loss: 0.6844 - val_accuracy: 0.7867\n",
      "Epoch 155/256\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3825 - accuracy: 0.9971 - val_loss: 0.6843 - val_accuracy: 0.7867\n",
      "Epoch 156/256\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4019 - accuracy: 0.9971 - val_loss: 0.6840 - val_accuracy: 0.7867\n",
      "Epoch 157/256\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3851 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 0.7733\n",
      "Epoch 158/256\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3923 - accuracy: 0.9886 - val_loss: 0.6832 - val_accuracy: 0.7733\n",
      "Epoch 159/256\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3855 - accuracy: 0.9886 - val_loss: 0.6830 - val_accuracy: 0.7733\n",
      "Epoch 160/256\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3979 - accuracy: 0.9971 - val_loss: 0.6828 - val_accuracy: 0.7733\n",
      "Epoch 161/256\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3822 - accuracy: 0.9971 - val_loss: 0.6826 - val_accuracy: 0.7733\n",
      "Epoch 162/256\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3837 - accuracy: 0.9943 - val_loss: 0.6824 - val_accuracy: 0.7867\n",
      "Epoch 163/256\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3838 - accuracy: 0.9971 - val_loss: 0.6819 - val_accuracy: 0.7733\n",
      "Epoch 164/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3795 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.7733\n",
      "Epoch 165/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3893 - accuracy: 0.9943 - val_loss: 0.6812 - val_accuracy: 0.7733\n",
      "Epoch 166/256\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3744 - accuracy: 1.0000 - val_loss: 0.6812 - val_accuracy: 0.7733\n",
      "Epoch 167/256\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3646 - accuracy: 0.9914 - val_loss: 0.6813 - val_accuracy: 0.7867\n",
      "Epoch 168/256\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.3819 - accuracy: 1.0000 - val_loss: 0.6815 - val_accuracy: 0.7867\n",
      "Epoch 169/256\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3841 - accuracy: 0.9971 - val_loss: 0.6814 - val_accuracy: 0.7867\n",
      "Epoch 170/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3735 - accuracy: 0.9971 - val_loss: 0.6809 - val_accuracy: 0.7867\n",
      "Epoch 171/256\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.3757 - accuracy: 1.0000 - val_loss: 0.6805 - val_accuracy: 0.7867\n",
      "Epoch 172/256\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3859 - accuracy: 0.9914 - val_loss: 0.6800 - val_accuracy: 0.7867\n",
      "Epoch 173/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3748 - accuracy: 0.9943 - val_loss: 0.6794 - val_accuracy: 0.7867\n",
      "Epoch 174/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3680 - accuracy: 0.9943 - val_loss: 0.6789 - val_accuracy: 0.7733\n",
      "Epoch 175/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3831 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.7733\n",
      "Epoch 176/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3630 - accuracy: 0.9971 - val_loss: 0.6782 - val_accuracy: 0.7733\n",
      "Epoch 177/256\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3765 - accuracy: 0.9971 - val_loss: 0.6782 - val_accuracy: 0.7733\n",
      "Epoch 178/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3625 - accuracy: 0.9914 - val_loss: 0.6782 - val_accuracy: 0.7867\n",
      "Epoch 179/256\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3782 - accuracy: 0.9971 - val_loss: 0.6784 - val_accuracy: 0.7867\n",
      "Epoch 180/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3692 - accuracy: 1.0000 - val_loss: 0.6787 - val_accuracy: 0.7867\n",
      "Epoch 181/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3853 - accuracy: 0.9886 - val_loss: 0.6788 - val_accuracy: 0.7867\n",
      "Epoch 182/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3766 - accuracy: 0.9943 - val_loss: 0.6789 - val_accuracy: 0.7867\n",
      "Epoch 183/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3731 - accuracy: 0.9943 - val_loss: 0.6787 - val_accuracy: 0.7867\n",
      "Epoch 184/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3673 - accuracy: 0.9943 - val_loss: 0.6782 - val_accuracy: 0.7867\n",
      "Epoch 185/256\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.3587 - accuracy: 0.9914 - val_loss: 0.6776 - val_accuracy: 0.7867\n",
      "Epoch 186/256\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3661 - accuracy: 0.9943 - val_loss: 0.6772 - val_accuracy: 0.7867\n",
      "Epoch 187/256\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3779 - accuracy: 0.9943 - val_loss: 0.6769 - val_accuracy: 0.7867\n",
      "Epoch 188/256\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3709 - accuracy: 0.9971 - val_loss: 0.6765 - val_accuracy: 0.7867\n",
      "Epoch 189/256\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3707 - accuracy: 0.9914 - val_loss: 0.6760 - val_accuracy: 0.7733\n",
      "Epoch 190/256\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3630 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 0.7600\n",
      "Epoch 191/256\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3573 - accuracy: 1.0000 - val_loss: 0.6752 - val_accuracy: 0.7600\n",
      "Epoch 192/256\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3648 - accuracy: 0.9971 - val_loss: 0.6748 - val_accuracy: 0.7600\n",
      "Epoch 193/256\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3697 - accuracy: 0.9943 - val_loss: 0.6747 - val_accuracy: 0.7600\n",
      "Epoch 194/256\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3563 - accuracy: 0.9971 - val_loss: 0.6746 - val_accuracy: 0.7733\n",
      "Epoch 195/256\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3703 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 0.7733\n",
      "Epoch 196/256\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3548 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.7733\n",
      "Epoch 197/256\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3502 - accuracy: 0.9971 - val_loss: 0.6740 - val_accuracy: 0.7733\n",
      "Epoch 198/256\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3556 - accuracy: 0.9971 - val_loss: 0.6738 - val_accuracy: 0.7733\n",
      "Epoch 199/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3562 - accuracy: 0.9971 - val_loss: 0.6735 - val_accuracy: 0.7733\n",
      "Epoch 200/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3529 - accuracy: 0.9914 - val_loss: 0.6732 - val_accuracy: 0.7733\n",
      "Epoch 201/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3589 - accuracy: 0.9943 - val_loss: 0.6731 - val_accuracy: 0.7733\n",
      "Epoch 202/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3604 - accuracy: 1.0000 - val_loss: 0.6732 - val_accuracy: 0.7733\n",
      "Epoch 203/256\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3624 - accuracy: 0.9886 - val_loss: 0.6735 - val_accuracy: 0.7867\n",
      "Epoch 204/256\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.3492 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.7867\n",
      "Epoch 205/256\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3560 - accuracy: 0.9971 - val_loss: 0.6730 - val_accuracy: 0.7733\n",
      "Epoch 206/256\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3552 - accuracy: 0.9914 - val_loss: 0.6724 - val_accuracy: 0.7733\n",
      "Epoch 207/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3647 - accuracy: 1.0000 - val_loss: 0.6718 - val_accuracy: 0.7733\n",
      "Epoch 208/256\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3464 - accuracy: 0.9943 - val_loss: 0.6714 - val_accuracy: 0.7733\n",
      "Epoch 209/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3488 - accuracy: 0.9971 - val_loss: 0.6709 - val_accuracy: 0.7733\n",
      "Epoch 210/256\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3572 - accuracy: 0.9943 - val_loss: 0.6705 - val_accuracy: 0.7733\n",
      "Epoch 211/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3521 - accuracy: 0.9943 - val_loss: 0.6702 - val_accuracy: 0.7733\n",
      "Epoch 212/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3465 - accuracy: 0.9943 - val_loss: 0.6700 - val_accuracy: 0.7733\n",
      "Epoch 213/256\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3481 - accuracy: 0.9971 - val_loss: 0.6699 - val_accuracy: 0.7733\n",
      "Epoch 214/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3435 - accuracy: 0.9971 - val_loss: 0.6697 - val_accuracy: 0.7733\n",
      "Epoch 215/256\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3469 - accuracy: 1.0000 - val_loss: 0.6694 - val_accuracy: 0.7733\n",
      "Epoch 216/256\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3432 - accuracy: 1.0000 - val_loss: 0.6692 - val_accuracy: 0.7733\n",
      "Epoch 217/256\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3469 - accuracy: 0.9971 - val_loss: 0.6688 - val_accuracy: 0.7733\n",
      "Epoch 218/256\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3497 - accuracy: 0.9943 - val_loss: 0.6686 - val_accuracy: 0.7733\n",
      "Epoch 219/256\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3380 - accuracy: 1.0000 - val_loss: 0.6685 - val_accuracy: 0.7733\n",
      "Epoch 220/256\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.3452 - accuracy: 1.0000 - val_loss: 0.6682 - val_accuracy: 0.7733\n",
      "Epoch 221/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3415 - accuracy: 1.0000 - val_loss: 0.6680 - val_accuracy: 0.7733\n",
      "Epoch 222/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3355 - accuracy: 0.9971 - val_loss: 0.6680 - val_accuracy: 0.7733\n",
      "Epoch 223/256\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3458 - accuracy: 0.9943 - val_loss: 0.6678 - val_accuracy: 0.7733\n",
      "Epoch 224/256\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3425 - accuracy: 0.9971 - val_loss: 0.6677 - val_accuracy: 0.7733\n",
      "Epoch 225/256\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3474 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 0.7733\n",
      "Epoch 226/256\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3419 - accuracy: 0.9971 - val_loss: 0.6676 - val_accuracy: 0.7733\n",
      "Epoch 227/256\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.3447 - accuracy: 0.9914 - val_loss: 0.6673 - val_accuracy: 0.7733\n",
      "Epoch 228/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3406 - accuracy: 1.0000 - val_loss: 0.6669 - val_accuracy: 0.7733\n",
      "Epoch 229/256\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3451 - accuracy: 1.0000 - val_loss: 0.6667 - val_accuracy: 0.7733\n",
      "Epoch 230/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3291 - accuracy: 0.9971 - val_loss: 0.6667 - val_accuracy: 0.7733\n",
      "Epoch 231/256\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3359 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.7733\n",
      "Epoch 232/256\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3439 - accuracy: 0.9886 - val_loss: 0.6667 - val_accuracy: 0.7600\n",
      "Epoch 233/256\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3473 - accuracy: 0.9943 - val_loss: 0.6662 - val_accuracy: 0.7733\n",
      "Epoch 234/256\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3385 - accuracy: 0.9971 - val_loss: 0.6657 - val_accuracy: 0.7733\n",
      "Epoch 235/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3294 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.7733\n",
      "Epoch 236/256\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3425 - accuracy: 1.0000 - val_loss: 0.6650 - val_accuracy: 0.7733\n",
      "Epoch 237/256\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3295 - accuracy: 0.9971 - val_loss: 0.6648 - val_accuracy: 0.7600\n",
      "Epoch 238/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3369 - accuracy: 0.9971 - val_loss: 0.6649 - val_accuracy: 0.7600\n",
      "Epoch 239/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3316 - accuracy: 0.9943 - val_loss: 0.6650 - val_accuracy: 0.7600\n",
      "Epoch 240/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3400 - accuracy: 0.9971 - val_loss: 0.6651 - val_accuracy: 0.7600\n",
      "Epoch 241/256\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3278 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.7600\n",
      "Epoch 242/256\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3223 - accuracy: 0.9971 - val_loss: 0.6647 - val_accuracy: 0.7600\n",
      "Epoch 243/256\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3373 - accuracy: 0.9971 - val_loss: 0.6641 - val_accuracy: 0.7600\n",
      "Epoch 244/256\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3328 - accuracy: 0.9971 - val_loss: 0.6637 - val_accuracy: 0.7600\n",
      "Epoch 245/256\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3388 - accuracy: 0.9971 - val_loss: 0.6633 - val_accuracy: 0.7600\n",
      "Epoch 246/256\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3374 - accuracy: 1.0000 - val_loss: 0.6629 - val_accuracy: 0.7733\n",
      "Epoch 247/256\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.3373 - accuracy: 1.0000 - val_loss: 0.6627 - val_accuracy: 0.7733\n",
      "Epoch 248/256\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3216 - accuracy: 1.0000 - val_loss: 0.6626 - val_accuracy: 0.7600\n",
      "Epoch 249/256\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3261 - accuracy: 0.9971 - val_loss: 0.6624 - val_accuracy: 0.7733\n",
      "Epoch 250/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3399 - accuracy: 0.9943 - val_loss: 0.6620 - val_accuracy: 0.7733\n",
      "Epoch 251/256\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3332 - accuracy: 1.0000 - val_loss: 0.6616 - val_accuracy: 0.7733\n",
      "Epoch 252/256\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3298 - accuracy: 0.9943 - val_loss: 0.6613 - val_accuracy: 0.7733\n",
      "Epoch 253/256\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3235 - accuracy: 0.9971 - val_loss: 0.6609 - val_accuracy: 0.7733\n",
      "Epoch 254/256\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3189 - accuracy: 0.9971 - val_loss: 0.6605 - val_accuracy: 0.7733\n",
      "Epoch 255/256\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3230 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.7733\n",
      "Epoch 256/256\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3244 - accuracy: 1.0000 - val_loss: 0.6600 - val_accuracy: 0.7733\n"
     ]
    }
   ],
   "source": [
    "#traingin the random forest model \n",
    "history = train_model(model, x_train, y_train, epochs, x_val, y_val, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "save_model(model, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
